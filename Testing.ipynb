{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import dok_matrix\n",
    "import scipy.sparse.linalg as ssl\n",
    "import scipy.sparse as scs\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load in the data. Using the Jeapardy data as it's small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/JEOPARDY_CSV.csv')\n",
    "data = data[:1000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4680, '2004-12-31', 'Jeopardy!', 'HISTORY', '$200',\n",
       "       \"For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\",\n",
       "       'Copernicus'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import scipy.sparse as scs\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def unique_words(list sentences):\n",
    "    cdef dict words = {}\n",
    "    cdef int n = len(sentences)\n",
    "    cdef int i, j\n",
    "    for i in range(n):\n",
    "        sent_list = [w.lower() for w in sentences[i].split(' ')]\n",
    "        clean_sent_list = []\n",
    "        for j in range(len(sent_list)):\n",
    "            newword = ''\n",
    "            for char in sent_list[j]:\n",
    "                if char in alphabet:\n",
    "                    newword += char\n",
    "            clean_sent_list.append(newword)\n",
    "        for word in clean_sent_list:\n",
    "            if word != '':\n",
    "                try:\n",
    "                    words[word] += 1\n",
    "                except KeyError:\n",
    "                    words[word] = 1\n",
    "    wordlist = sorted(words.keys())\n",
    "    return wordlist, len(wordlist), words\n",
    "\n",
    "# Use tf-idf\n",
    "# https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "def populate_doc_matrix(docmatrix, wordlist, word_freq, np.ndarray data):\n",
    "    cdef int n = len(data)   # number of documents\n",
    "    cdef int i, j, k, m\n",
    "    # construct word index first\n",
    "    # This tells us (for any word) what index it is in in document\n",
    "    print('Constructing Word Reference')\n",
    "    wordref = {}\n",
    "    for i in range(len(wordlist)):\n",
    "        wordref[wordlist[i]] = i\n",
    "    # Now populate sparse matrix\n",
    "    print('Populating Sparse Matrix')\n",
    "    for i in range(n):\n",
    "        for j in range(2):\n",
    "            words = [w.lower() for w in data[i, j].split(' ') if w != '']\n",
    "            m = len(words)\n",
    "            for k in range(m):\n",
    "                word = words[k]\n",
    "                cword = ''\n",
    "                for char in word:\n",
    "                    if char in alphabet:\n",
    "                        cword += char\n",
    "                if cword != '':\n",
    "                    docmatrix[i, wordref[cword]] += 1\n",
    "    # finish weighting\n",
    "    print('Weighting Matrix')\n",
    "    m, n = docmatrix.shape\n",
    "    weighted_docmatrix = dok_matrix((m, n), dtype=float)\n",
    "    for i in range(n):\n",
    "        weighted_docmatrix[:, i] = docmatrix[:, i] * np.log(m / word_freq[wordlist[i]])\n",
    "    return weighted_docmatrix, wordref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words, n, wordfreq = unique_words(list(np.concatenate((data[[' Question']].values[:, 0],\n",
    "                                  data[[' Answer']].values[:, 0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Documents (m) by 5244 Unique Words (n)\n",
      "\n",
      "Top 100 Most Frequent Words:the,this,of,a,in,to,for,is,on,was,its,from,as,with,that,an,his,you,these,he,by,it,at,first,one,name,or,city,and,named,state,i,s,are,john,man,country,us,who,have,be,your,has,word,like,new,her,not,seen,called,when,hrefhttpwwwjarchivecommediadjjpg,had,out,were,here,about,can,clue,known,all,show,she,war,but,years,th,if,which,crew,make,now,film,made,wrote,series,may,type,island,more,used,area,than,began,queen,most,also,book,some,term,became,flag,said,part,river,youre,little,george,whose,him\n"
     ]
    }
   ],
   "source": [
    "print('{} Documents (m) by {} Unique Words (n)\\n\\nTop 100 Most Frequent Words:{}'.format(\n",
    "        m, n, ','.join([tup[0] for tup in sorted(wordfreq.items(), key=lambda tup: -tup[1])[:100]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docmatrix = dok_matrix((m, n), dtype=float)   # m-docs, n-unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Word Reference\n",
      "Populating Sparse Matrix\n",
      "Weighting Matrix\n"
     ]
    }
   ],
   "source": [
    "ndocterm, wordref = populate_doc_matrix(docmatrix, words, wordfreq,\n",
    "                                data[[' Question', ' Answer']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x5244 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14157 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndocterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5244, 20), (20,), (20, 1000))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, vt = ssl.svds(ndocterm.T, k=20)\n",
    "u.shape, s.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('umatrix.npy', u)\n",
    "np.save('smatrix.npy', s)\n",
    "np.save('vtmatrix.npy', vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have our $k$th-order decomposition, let's query the word \"Species\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4384"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordref['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t  satrix.npy   Testing.html   umatrix.npy\r\n",
      "proposal  smatrix.npy  Testing.ipynb  vtmatrix.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05452245, -0.00216872,  0.00831265, ...,  0.02053064,\n",
       "         0.01959931, -0.03883994],\n",
       "       [ 0.02404747, -0.01370522,  0.02219454, ...,  0.00463428,\n",
       "         0.00127721, -0.02248268],\n",
       "       [ 0.01949402,  0.00652029,  0.00995533, ..., -0.01139821,\n",
       "         0.01296431, -0.02839199],\n",
       "       ..., \n",
       "       [ 0.04080266, -0.00356032, -0.01054592, ..., -0.00705405,\n",
       "         0.00661091, -0.02353832],\n",
       "       [-0.01053368,  0.04073003, -0.01327792, ...,  0.02682542,\n",
       "         0.00499936, -0.02426648],\n",
       "       [ 0.00029609, -0.01917808, -0.02569479, ..., -0.00053521,\n",
       "         0.03182219, -0.03529649]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./umatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
